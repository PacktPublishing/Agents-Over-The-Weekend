{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyeCwDW69Zf3"
      },
      "source": [
        "# Codes for bootcamp talk: Advanced LLM & Agent Systems Bootcamp*\n",
        "\\*This notebook is outdated, see this notebook: [codes_for_Lior_Bootcamp_talk_sept2025_demo1.ipynb](https://github.com/PacktPublishing/Agents-Over-The-Weekend/blob/main/Lior_Gazit/workshop_september_2025/codes_for_Lior_Bootcamp_talk_sept2025_demo1.ipynb)  \n",
        "By: [Lior Gazit](https://github.com/LiorGazit).  \n",
        "Repo: [Agents-Over-The-Weekend](https://github.com/PacktPublishing/Agents-Over-The-Weekend/)  \n",
        "Running LLMs locally for free: This code leverages [this code repo](https://github.com/LiorGazit/agentic_actions_locally_hosted/blob/main/spin_up_LLM.py) that is dedicated to running open and free LLMs locally.  \n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PacktPublishing/Agents-Over-The-Weekend/blob/main/Lior_Gazit/workshop_june_2025/codes_for_Lior_Bootcamp_talk_demo1.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a> (pick a GPU Colab session for fastest computing)  \n",
        "\n",
        "```\n",
        "Disclaimer: The content and ideas presented in this notebook are solely those of the author, Lior Gazit, and do not represent the views or intellectual property of the author's employer.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn9qIRLS9Zf7"
      },
      "source": [
        "Installing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMpPyY829Zf9",
        "outputId": "a4dafeeb-4283-479a-daed-af04f3743a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.7/367.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.4/306.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install sentence-transformers faiss-cpu langchain tiktoken langsmith langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uU75SUy9ZgA"
      },
      "source": [
        "If this notebook is run outside of the repo's codes, get the necessary code from the remote repo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVDmCWnO9ZgB",
        "outputId": "39c43d06-d3be-4df7-bcb0-b9633ccad9d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded spin_up_LLM.py from GitHub\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# If the module isn't already present (e.g. in Colab), fetch it from GitHub\n",
        "if not os.path.exists(\"spin_up_LLM.py\"):\n",
        "    url = \"https://raw.githubusercontent.com/LiorGazit/agentic_actions_locally_hosted/refs/heads/main/spin_up_LLM.py\"\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    with open(\"spin_up_LLM.py\", \"w\") as f:\n",
        "        f.write(resp.text)\n",
        "    print(\"Downloaded spin_up_LLM.py from GitHub\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnAGhgi19ZgC"
      },
      "source": [
        "## Demo 1: RAG Pipeline with Chained Prompt Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb3_eQNB9ZgC"
      },
      "source": [
        "Setting up the Vector Store and RAG pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543,
          "referenced_widgets": [
            "3bbb579e699b4509a300cfde9d4416b0",
            "e70894b0bbbf44cbb1379fc9115f4a01",
            "067359d8f20b4f0b8d56387b6632994d",
            "01dc31746e2649c09d5e1eb5e31e7b9c",
            "8c07d59c7d0546af952cf84fe23cc89b",
            "f109c3ea77384b16b59aa4acf8eb1d24",
            "0e4234ab93214c5aba7d08bda5b5764f",
            "6530d743239e4c02ba9a9ce77547b58b",
            "a681a35ceaf2482b9dfc3f0553aa40e4",
            "54a00ee030874935a4ee6dc707700243",
            "09283db0f334405a8bbe8bff3c603a8d",
            "c5530c844d3843dfbe824754fb527950",
            "779e49fc3f864b6b9e4684259a78079a",
            "4857bc42984343cfb049c1ee8e347548",
            "1afde07e353540279b69181812a7c7ef",
            "2ffbdf2216b74f7e9bc5f3ec120a6d2a",
            "c70d95289dc747d1ab3583f8fa2d7f97",
            "2df0f61ec3cc498096baa899ef3344d2",
            "903acc697aef4e1f8381094d45c1145a",
            "d5d4a9a3eb6d47c3a6324d00cb07932e",
            "bbbb5530dfa84ae8ad52c8cc0ed96e83",
            "9a67c576c2864e318d5c7185f0b00661",
            "fb5086d65b15468ca14ebc71d63b6604",
            "3cf70646f6fa4bc8b5ba94c05c6e1621",
            "3e4d89b1d4af465a9b0cac9e967e3bd4",
            "707e86889026468cb831c59189d8e00e",
            "5b4fd9db6fd54a238d294c984b66e9c1",
            "49872c6f63ed452aaed111e90cf9c443",
            "35510638a95b47dbb81d6ea8c181e4c7",
            "7971987ebf5f4643a2ff3b26d4ab38f3",
            "815093def1284085bf6d505edb9a4054",
            "ae3a24209d044ec0897c8b5d2e2c40e0",
            "15026837b21544d787fa3dc2e2d9024c",
            "5f74e064166c49a2afe344240b175fe7",
            "586224878072430597da7ad48395b076",
            "7dd0f2a6e9a64c9b9efa3efcb1f3e4b6",
            "707ae6ba328449af892a1225c370fe27",
            "ef30c2ef177e4ba7bcc1ff48498f471e",
            "c29ab0d2b162492a990699cb02345f51",
            "3b7cab1d061e45969c1a4ba8878d4c1a",
            "d4e64fb0d9464277906bd1f78fbda2e8",
            "6b9e01aea9974f1f95c584fac7968c4f",
            "57af738eafb642c4825e7bbbad8b7a5a",
            "aac6b773d52d475cb8f0ec205ff9029b",
            "911c6eed360b43c39cfa040528626f99",
            "ed29b89496ae4511aafda6ff4efc3fad",
            "8a53e6ecf8f9435093f17bb6a1445361",
            "faad56d7f40c493d89d2eb3a21fa7860",
            "ae77524151234019bcfc3a9abcd883d2",
            "a53fab945e92457abb6e8bbbd0d1017b",
            "f82839109fe2437eb11250aa2ba6cd3b",
            "62791dbcb1d1456dba472e4bc1999eb1",
            "eb2cafec44584041a280a9123139a1f6",
            "27b5e95bfd76477fae063a5971cc1f3a",
            "fd0935998ac6446fa1e1306f17e476da",
            "ac8a43d19ea34f9c8fddb1e1f2a52948",
            "d61a62358d334611a2198da2323df077",
            "f4853f3af83b4f7d9fe975cd49a85e09",
            "5c8efd3ab1ad4b4dab81313e41ffbba4",
            "f8043c14cb9842ac8ab03547a617a561",
            "85991f62ea0143089a5c1b59f1935e61",
            "4915896ef4d74038af49d7437ea8f074",
            "4d389180cf3e42f4b2d31cd04c4f4333",
            "e0a3b81b87184180bba28e239440cee2",
            "8500a77e248d4bec9ba0d38f399fee64",
            "325f3eac097c4e05b2de3ce82e32b9be",
            "d51043f26b8e43cc8888ad8ecf1ae432",
            "a85937ff8b304c1f97b52bee4a58b087",
            "5e43a5e9fd1c4922ba3348187c78c760",
            "8d0c93cc362c424284948b2b5ca476ee",
            "494c73a08d054e4a8f00f57f294ef48b",
            "5ff674a20ffa44b7b908d2f47ce8e88f",
            "b1f3ea9dfe00463fab332f19ac80b10b",
            "272bbc8d89974234a90735f9243be04c",
            "21bb3021f8684c638b6d7aea2e2cb79d",
            "3ba852d1a39d46639d86281a15c810fb",
            "31c0b9aac2a1496a85632dd38c150430",
            "9499d047b1844ea5a6421bb3317ca820",
            "bd5f64d7d9984b4599bed0135d690b7f",
            "08014eb614f34dc9a1d8264ffe3aa0ae",
            "8e08d4fc705c469a944e182028d07f03",
            "7c0aa18ef445425c839993d6444b0bd6",
            "1c7593ec46f24e1bb332e1a5c8556984",
            "52b7c6d2228c4a00b96e80b006440ddc",
            "5135c34c2f9c4ee89e08fbcd624943f4",
            "3dc6f8732b09464db882ebc65847845b",
            "caada4b5487d4ef0a360849000ba21a1",
            "a7076e6d68f34464bf430ea94397ae24",
            "bf93066126f640bb821164949606bee9",
            "6a8ecc257440416d9c9a2a260ea7fd9d",
            "f877c47b7ebc4b558bfd61ccb882d2c1",
            "ab6e3d30956945ac8e62f64ec52055b0",
            "764dc717b49445a1a717297592e367c6",
            "ae68dfa28e5b43dd886b2ac5aad52e43",
            "d5a96722693545b986abe861b1bb5efc",
            "b53814a2d4304882afc5e11a4355a436",
            "1995f093d7724b43ab5c2e75f82d033f",
            "9e68a7eb9fbb4f55bd1ebf1836372891",
            "e40afc73067c45fea641205b156c9f81",
            "28af4476caaa4e7595a67cafeb5e980e",
            "fa167b6934d44eb0aa86d516142c7e46",
            "d80170fdab5e490b9ced3f9c5945f55a",
            "b0c96e10118a4151bb544202f340a05a",
            "5c6cad2879c34dd2b8dbab2ff1461fdc",
            "0346a31a45ec49c5b9e044a7ff84b82d",
            "723a4c0e0ce546888b464fc73ed792fb",
            "5af38c44f5c649c5b23b92e5e3d4ea68",
            "f532e9b321294fb9a9353b977b540b4c",
            "9b7ae790749d415eabc397306fff061d",
            "ad42f81a7ecb44b78fd3e0fa75691cf8",
            "305fab3e38b1425f9d047ce23dbde99e",
            "f05303f6400d46f9a5ffbe94d179344b",
            "7e2fa88cd8c749dc8b98411667ed1fff",
            "41c048dbaa2147f281a99fa498be19c5",
            "3396d34a41e145b49d1768c6f730185a",
            "d9cf2b53b9fa4d679aedc6352d09e20f",
            "e223351555ce4bf5bdabbc1b05bd916c",
            "1059d7f2febf405cab76717d1a4c9dfe",
            "8988a4ddb8aa48b5af30848bf20face8",
            "25d4f550e20f4439a2a0ad4c9e7ed3c8",
            "d6df9b3866114bdaa39741a05f4b008a"
          ]
        },
        "id": "EEqyCnZQ9ZgD",
        "outputId": "63175a27-fa3c-4012-ee5a-d1f8427c689e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bbb579e699b4509a300cfde9d4416b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5530c844d3843dfbe824754fb527950",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5086d65b15468ca14ebc71d63b6604",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f74e064166c49a2afe344240b175fe7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "911c6eed360b43c39cfa040528626f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac8a43d19ea34f9c8fddb1e1f2a52948",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d51043f26b8e43cc8888ad8ecf1ae432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9499d047b1844ea5a6421bb3317ca820",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf93066126f640bb821164949606bee9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28af4476caaa4e7595a67cafeb5e980e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "305fab3e38b1425f9d047ce23dbde99e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Retrieved documents for context:\n",
            " [\"The company's earnings call mentioned concerns over increased production costs.\", 'Recent financial filings show revenue growth despite supply chain issues.']\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Example documents (could be clinical notes, financial filings, etc.)\n",
        "documents = [\n",
        "    \"Patient has diabetes type 2 and shows high glucose levels.\",\n",
        "    \"Recent financial filings show revenue growth despite supply chain issues.\",\n",
        "    \"Patient diagnosed with hypertension, recommended lifestyle changes.\",\n",
        "    \"The company's earnings call mentioned concerns over increased production costs.\",\n",
        "]\n",
        "\n",
        "# Step 1: Create embeddings using SentenceTransformer\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight embedding model\n",
        "\n",
        "# Generate embeddings for the documents\n",
        "document_embeddings = embedding_model.encode(documents)\n",
        "\n",
        "# Step 2: Setup FAISS vector store\n",
        "dimension = document_embeddings.shape[1]\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "faiss_index.add(document_embeddings)\n",
        "\n",
        "# Step 3: Define the retriever(query) function\n",
        "def retriever(query, top_k=2):\n",
        "    # Generate embedding for the query\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "\n",
        "    # Perform the similarity search in the FAISS index\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve the top_k most similar documents\n",
        "    retrieved_docs = [documents[idx] for idx in indices[0]]\n",
        "\n",
        "    return retrieved_docs\n",
        "\n",
        "# Example usage of the retriever\n",
        "query = \"What did the company say about production costs?\"\n",
        "context_docs = retriever(query)\n",
        "print(\"\\n\\nRetrieved documents for context:\\n\", context_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsLTVeT9ZgE"
      },
      "source": [
        "Prompting using a locally hosted LLM via Ollama:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hdYXyYZ9ZgF",
        "outputId": "dc179097-af57-46c1-f4a1-9e12c0f6e039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Installing Ollama...\n",
            "🚀 Starting Ollama server...\n",
            "→ Ollama PID: 3037\n",
            "⏳ Waiting for Ollama to be ready…\n",
            "🚀 Pulling model 'gemma3'…\n",
            "Available models:\n",
            "NAME             ID              SIZE      MODIFIED               \n",
            "gemma3:latest    a2af6cc3eb7f    3.3 GB    Less than a second ago    \n",
            "\n",
            "🚀 Installing langchain-ollama…\n",
            "\n",
            "\n",
            "\n",
            "A: The patient has diabetes type 2 and hypertension.\n"
          ]
        }
      ],
      "source": [
        "from spin_up_LLM import spin_up_LLM\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "query = \"What is the patient's diagnosis given these notes?\"\n",
        "context_docs = retriever(query)\n",
        "question = f\"Using the following context, answer the question:\\n\\n{context_docs}\\n\\nQ: {query}\\n\\n---\\nA:\"\n",
        "local_llm = spin_up_LLM(chosen_llm=\"gemma3\")\n",
        "\n",
        "answer_local = local_llm.generate([question])\n",
        "print(\"\\n\\n\")\n",
        "print(answer_local.generations[0][0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK1oYpXy9ZgG"
      },
      "source": [
        "Prompting using OpenAI's API (paid) route:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv5oEytT9ZgG",
        "outputId": "ca17e125-f326-4874-848b-0fa3ac6c1ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI API key: ··········\n",
            "\n",
            "\n",
            "\n",
            "The patient's diagnoses are diabetes type 2 and hypertension.\n"
          ]
        }
      ],
      "source": [
        "# In Colab, use getpass to securely prompt for your API key\n",
        "from getpass import getpass\n",
        "import openai\n",
        "\n",
        "openai.api_key = getpass(\"Paste your OpenAI API key: \")\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\",\"content\":\"You are a medical assistant.\"},\n",
        "        {\"role\":\"user\",  \"content\": question}\n",
        "    ]\n",
        ")\n",
        "\n",
        "answer_api = response.choices[0].message.content\n",
        "print(\"\\n\\n\")\n",
        "print(answer_api)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
